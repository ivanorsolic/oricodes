{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from donkeycar.parts.keras import KerasPilot\n",
    "from tensorflow.python.keras.layers import Input, Dense\n",
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Convolution2D, Convolution2D, MaxPooling2D, Reshape, BatchNormalization\n",
    "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Cropping2D, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ROI crop helper function\n",
    "\n",
    "def adjust_input_shape(input_shape, roi_crop):\n",
    "    height = input_shape[0]\n",
    "    new_height = height - roi_crop[0] - roi_crop[1]\n",
    "    return (new_height, input_shape[1], input_shape[2])\n",
    "\n",
    "# The definition of our model\n",
    "\n",
    "# Also, be sure to name every convolutional layer you have as \"convx\" (x ∈ ℕ)\n",
    "\n",
    "def customModel(num_outputs=2, input_shape=(160,120,3), roi_crop=(0,0)):\n",
    "\n",
    "    input_shape = adjust_input_shape(input_shape, roi_crop)\n",
    "    img_in = Input(shape=input_shape, name='img_in')\n",
    "    x = img_in\n",
    "    \n",
    "    # Dropout rate\n",
    "\n",
    "    keep_prob = 0.5\n",
    "    rate = 1 - keep_prob\n",
    "    \n",
    "    # Convolutional Layer 1\n",
    "\n",
    "    x = Convolution2D(filters=12, kernel_size=5, strides=(2, 2), activation='relu', name=\"conv1\")(x)\n",
    "    x = Dropout(rate)(x)\n",
    "\n",
    "    # Convolutional Layer 2\n",
    "\n",
    "    x = Convolution2D(filters=24, kernel_size=5, strides=(2, 2), activation='relu', name=\"conv2\")(x)\n",
    "    x = Dropout(rate)(x)\n",
    "\n",
    "    # Convolutional Layer 3\n",
    "\n",
    "    x = Convolution2D(filters=48, kernel_size=5, strides=(2, 2), activation='relu', name=\"conv3\")(x)\n",
    "    x = Dropout(rate)(x)\n",
    "\n",
    "    # Convolutional Layer 4\n",
    "\n",
    "    x = Convolution2D(filters=64, kernel_size=3, strides=(1, 1), activation='relu', name=\"conv4\")(x)\n",
    "    x = Dropout(rate)(x)\n",
    "\n",
    "    # Convolutional Layer 5\n",
    "\n",
    "    x = Convolution2D(filters=64, kernel_size=3, strides=(1, 1), activation='relu', name=\"conv5\")(x)\n",
    "    x = Dropout(rate)(x)\n",
    "\n",
    "    # Flatten Layers\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Fully Connected Layer 1\n",
    "\n",
    "    x = Dense(100, activation='relu')(x)\n",
    "\n",
    "    # Fully Connected Layer 2\n",
    "\n",
    "    x = Dense(50, activation='relu')(x)\n",
    "\n",
    "    # Fully Connected Layer 3\n",
    "\n",
    "    x = Dense(25, activation='relu')(x)\n",
    "    x = Dense(10, activation='relu')(x)\n",
    "    x = Dense(5, activation='relu')(x)\n",
    "    outputs = []\n",
    "    \n",
    "    for i in range(num_outputs):\n",
    "        outputs.append(Dense(1, activation='linear', name='n_outputs' + str(i))(x))\n",
    "        \n",
    "    model = Model(inputs=[img_in], outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = customModel()\n",
    "# Pass the path to your trained .h5 file here\n",
    "model.load_weights('models/nvidiaSmall.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_in = Input(shape=(160,120,3), name='img_in')\n",
    "\n",
    "x = img_in\n",
    "x = Convolution2D(filters=12, kernel_size=5, strides=(2, 2), activation='relu', name=\"conv1\")(x)\n",
    "x = Convolution2D(filters=24, kernel_size=5, strides=(2, 2), activation='relu', name=\"conv2\")(x)\n",
    "x = Convolution2D(filters=48, kernel_size=5, strides=(2, 2), activation='relu', name=\"conv3\")(x)\n",
    "x = Convolution2D(filters=64, kernel_size=3, strides=(1, 1), activation='relu', name=\"conv4\")(x)\n",
    "lastConvLayer = Convolution2D(filters=64, kernel_size=3, strides=(1, 1), activation='relu', name=\"conv5\")(x)  \n",
    "\n",
    "convolution_part = Model(inputs=[img_in], outputs=[lastConvLayer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have more than 5 layers, or less than 5 layers, edit the number here\n",
    "\n",
    "numberOfConvLayers = 5\n",
    "for layer_num in range(1, numberOfConvLayers):\n",
    "    convolution_part.get_layer('conv' + str(layer_num)).set_weights(model.get_layer('conv' + str(layer_num)).get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "inp = convolution_part.input  # input placeholder\n",
    "\n",
    "outputs = [layer.output for layer in convolution_part.layers[1:]] # all layer outputs\n",
    "\n",
    "functors = K.function([inp], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "# 3x3 kernel with all ones\n",
    "\n",
    "kernel_3x3 = tf.constant(np.array([\n",
    "        [[[1]], [[1]], [[1]]], \n",
    "        [[[1]], [[1]], [[1]]], \n",
    "        [[[1]], [[1]], [[1]]]\n",
    "]), tf.float32)\n",
    "\n",
    "# 5x5 kernel with all ones\n",
    "\n",
    "kernel_5x5 = tf.constant(np.array([\n",
    "        [[[1]], [[1]], [[1]], [[1]], [[1]]], \n",
    "        [[[1]], [[1]], [[1]], [[1]], [[1]]], \n",
    "        [[[1]], [[1]], [[1]], [[1]], [[1]]],\n",
    "        [[[1]], [[1]], [[1]], [[1]], [[1]]],\n",
    "        [[[1]], [[1]], [[1]], [[1]], [[1]]]\n",
    "]), tf.float32)\n",
    "\n",
    "# Based on the layers in your model, you should assign the kernel sizes you're using at each layer here.\n",
    "\n",
    "# E.g. I'm using a 3x3 kernel in my last two layers, and a 3x3 in my first three layers\n",
    "\n",
    "layers_kernels = {5: kernel_3x3, 4: kernel_3x3, 3: kernel_5x5, 2: kernel_5x5, 1: kernel_5x5}\n",
    "\n",
    "# Same goes here for the strides you're using in your layers\n",
    "\n",
    "layers_strides = {5: [1, 1, 1, 1], 4: [1, 1, 1, 1], 3: [1, 2, 2, 1], 2: [1, 2, 2, 1], 1: [1, 2, 2, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_visualisation_mask(input_image):\n",
    "    activations = functors([np.array([input_image])])\n",
    "    activations = [np.reshape(input_image, (1, input_image.shape[0], input_image.shape[1], input_image.shape[2]))] + activations\n",
    "    upscaled_activation = np.ones((8, 13))\n",
    "    for layer in [5, 4, 3, 2, 1]: # Edit if you have a different # of layers \n",
    "\n",
    "        averaged_activation = np.mean(activations[layer], axis=3).squeeze(axis=0) * upscaled_activation\n",
    "        output_shape = (activations[layer - 1].shape[1], activations[layer - 1].shape[2])\n",
    "        x = tf.constant(\n",
    "            np.reshape(averaged_activation, (1,averaged_activation.shape[0],averaged_activation.shape[1],1)),\n",
    "            tf.float32\n",
    "        )\n",
    "        conv = tf.nn.conv2d_transpose(\n",
    "        \tx, layers_kernels[layer],\n",
    "            output_shape=(1,output_shape[0],output_shape[1], 1), \n",
    "            strides=layers_strides[layer], \n",
    "            padding='VALID'\n",
    "        )\n",
    "        with tf.Session() as session:\n",
    "            result = session.run(conv)\n",
    "        upscaled_activation = np.reshape(result, output_shape)\n",
    "    final_visualisation_mask = upscaled_activation\n",
    "    return (final_visualisation_mask - np.min(final_visualisation_mask))/(np.max(final_visualisation_mask) - np.min(final_visualisation_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def save_movie_gif(image_array, filename='output.gif', fps=30):\n",
    "    dpi = 72.0\n",
    "    xpixels, ypixels = image_array[0].shape[0], image_array[0].shape[1]\n",
    "    fig = plt.figure(figsize=(ypixels/dpi, xpixels/dpi), dpi=dpi)\n",
    "    im = plt.figimage(image_array[0])\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_array(image_array[i])\n",
    "        return (im,)\n",
    "    \n",
    "    writer = animation.PillowWriter(fps=fps)\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=len(image_array))\n",
    "    anim.save(filename, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re, time, datetime\n",
    "# The path to your dataset\n",
    "pathToData = 'data/tub/'\n",
    "\n",
    "# Output video name\n",
    "output = \"saliency.gif\"\n",
    "\n",
    "# Output FPS\n",
    "fps = 60\n",
    "\n",
    "# Number of frames you want to use\n",
    "numberOfFrames = 600\n",
    "\n",
    "def sort_human(l):\n",
    "    convert = lambda text: float(text) if text.isdigit() else text\n",
    "    alphanum = lambda key: [convert(c) for c in re.split('([-+]?[0-9]*\\.?[0-9]*)', key)]\n",
    "    l.sort(key=alphanum)\n",
    "    return l\n",
    "\n",
    "inputImages = []\n",
    "alpha = 0.004\n",
    "beta = 1.0 - alpha\n",
    "counter = 0\n",
    "print(\"Generating %ds of video.\" % (numberOfFrames/fps))\n",
    "accumulatedTime = 0\n",
    "start = time.time()\n",
    "for path in sort_human(glob.glob(pathToData + '*.jpg')):\n",
    "    inputImage = cv2.imread(path)\n",
    "    salient_mask = compute_visualisation_mask(inputImage)\n",
    "    salient_mask_stacked = np.dstack((salient_mask,salient_mask))\n",
    "    salient_mask_stacked = np.dstack((salient_mask_stacked,salient_mask))\n",
    "    blend = cv2.addWeighted(inputImage.astype('float32'), alpha, salient_mask_stacked, beta, 0.0)\n",
    "    inputImages.append(blend)\n",
    "    counter += 1\n",
    "\n",
    "    if counter >= numberOfFrames:\n",
    "        break\n",
    "\n",
    "    elif counter % 5 == 0:\n",
    "        end = time.time()\n",
    "        accumulatedTime += end - start\n",
    "        remainingSeconds = (accumulatedTime/counter)*(numberOfFrames-counter)\n",
    "        print(\"Generated %d/%d frames.\" % (counter, numberOfFrames))\n",
    "        print(\"Estimated time left: %dm:%ds.\" % divmod(remainingSeconds, 60))\n",
    "        print(\"Runtime so far: %dm:%ds.\" % divmod(accumulatedTime, 60))\n",
    "        start = time.time()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_movie_gif(inputImages, \"saliency.gif\", fps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}