<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home Page on Ori Codes</title>
    <link>http://localhost:1313/</link>
    <description>Recent content in Home Page on Ori Codes</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 01 Jan 0001 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Camera calibration: Explaining camera distortions</title>
      <link>http://localhost:1313/artificial-intelligence/camera-calibration/camera-distortions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/artificial-intelligence/camera-calibration/camera-distortions/</guid>
      <description>Since we&amp;rsquo;re using only cameras to obtain the entirety of data we&amp;rsquo;ll use to drive our car around the real world, we&amp;rsquo;re sure trusting them a lot. We&amp;rsquo;re trusting that they&amp;rsquo;ll provide us with accurate representations of real world 3D objects as 2D images we&amp;rsquo;ll feed into our neural network.&#xA;But we shouldn&amp;rsquo;t take that for granted. Cameras, albeit cheap and easy to use, come with all sorts of issues when it comes to mapping the 3D world onto a 2D sensor/image correctly.</description>
    </item>
    <item>
      <title>Creating our first custom network architecture</title>
      <link>http://localhost:1313/artificial-intelligence/custom-architecture/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/artificial-intelligence/custom-architecture/</guid>
      <description>Where do we even begin with the AI part of the project?&#xA;Well, I think it&amp;rsquo;d be a good idea to get the details of plugging a custom network into Donkey out of the way first.&#xA;If you remember the first autopilot we trained for sanity checking purposes, you&amp;rsquo;ll recall we&amp;rsquo;ve used an architecture that came with Donkey, whose source can be found at donkeycar/parts/keras.py.&#xA;And that&amp;rsquo;s pretty cool, we&amp;rsquo;ve already got a fair number of architectures to play around with out of the box.</description>
    </item>
    <item>
      <title>Simulator mod: High resolution images</title>
      <link>http://localhost:1313/artificial-intelligence/simulator-mod/high-resolution-images/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/artificial-intelligence/simulator-mod/high-resolution-images/</guid>
      <description>If we want to use the simulator to gather training data that&amp;rsquo;s larger than the default 160x120 image size, we&amp;rsquo;ll need to create a modified version of it.&#xA;Setting up the simulator locally First off, let&amp;rsquo;s clone (or fork) the original simulator Tawn Kramer made for Donkey from GitHub.&#xA;git clone --single-branch --branch donkey https://github.com/tawnkramer/sdsandbox If you&amp;rsquo;re wondering why aren&amp;rsquo;t I just using the git clone --branch command: it clones all branches, but checks out just the one you&amp;rsquo;ve passed to the flag.</description>
    </item>
    <item>
      <title>Augmenting the data with neural style transfer</title>
      <link>http://localhost:1313/draft-and-todo/data-augmentation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/draft-and-todo/data-augmentation/</guid>
      <description>Augmenting the data by generating mirrored images to counter (counter)clockwise bias on tracks.&#xA;Using neural style transfers to make the model more robust to lighting changes and real life track reflectiveness!&#xA;I&amp;rsquo;ve got this implemented, will think about writing it up! </description>
    </item>
    <item>
      <title>Camera calibration: Implementing the calibration and undistortion</title>
      <link>http://localhost:1313/artificial-intelligence/camera-calibration/implementing-camera-calibration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/artificial-intelligence/camera-calibration/implementing-camera-calibration/</guid>
      <description>First we&amp;rsquo;ll import the stuff we need and declare some variables:&#xA;import numpy as np import cv2, os, glob objectPoints = [] imagePoints = [] cameraIntrinsicValues = [] # Distortion coefficients cameraExtrinsicValues = [] Now we&amp;rsquo;ll implement the function that finds and returns the object and image points, given images of a chessboard:&#xA;def getObjectAndImagePoints(): global objectPoints, imagePoints # Number of inside corners per row and column cornersPerRow = 10 cornersPerColumn = 7 # Initializing the object points to zero chessboardObjectPoints = np.</description>
    </item>
    <item>
      <title>How is this website made?</title>
      <link>http://localhost:1313/extras/how-is-this-website-made/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/extras/how-is-this-website-made/</guid>
      <description>I made this site using:&#xA;Hugo - a static site generator that converts my markdown source files into this website. Learn - a theme for Hugo which provides this sweet design and other functions. Typora - for actually typing up all of the content you see here in markdown. Netlify - which hosts this site (and so many others) for free! And Visual Studio Code for some theme and Hugo source files editing.</description>
    </item>
    <item>
      <title>Parts: an overview</title>
      <link>http://localhost:1313/rc-car/parts_list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/rc-car/parts_list/</guid>
      <description>There’s a lot of, and I mean a lot of parts when it comes to building an RC car on your own. But in the context of building a self-driving RC car, here’s a brief overview of some of the stuff we’ll need:&#xA;You&amp;rsquo;ll want to have: A RC car (with some batteries) A PWM/Servo Driver (I2C + some jumper cables) A Jetson Nano A powerbank (+ some usb cables) A microSD card (and optionally an external SSD) A WiFi/BT m.</description>
    </item>
    <item>
      <title>Simulator mod: Custom RC model</title>
      <link>http://localhost:1313/artificial-intelligence/simulator-mod/custom-rc-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/artificial-intelligence/simulator-mod/custom-rc-model/</guid>
      <description>If you want to get better data for your RC, you should edit the default model that comes with the simulator. Most notably, you should edit the camera position, resolution and field of view. You can also add multiple cameras and edit the center of mass of your vehicle, as well as any other properties you think would make a difference if you wanted to use the simulator to pre-train the weights for your RC.</description>
    </item>
    <item>
      <title>Visualization: CNN Activations</title>
      <link>http://localhost:1313/artificial-intelligence/visualization/cnn-activations/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/artificial-intelligence/visualization/cnn-activations/</guid>
      <description>We already saw that the custom architecture/model works, but it&amp;rsquo;s surely not the best we could come up with. The question is, how can we improve its performance and get some intuition on how it works?&#xA;Seeing what the network sees One useful visual tool we could use is Donkey&amp;rsquo;s built in cnnactivations command. Per the official docs, it shows us the feature maps for each convolutional layer in the model we pass to it.</description>
    </item>
    <item>
      <title>Camera calibration: Calibrating the camera and undistorting images</title>
      <link>http://localhost:1313/artificial-intelligence/camera-calibration/calibrating-the-camera/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/artificial-intelligence/camera-calibration/calibrating-the-camera/</guid>
      <description>Finally, we can actually calibrate our camera and undistort our images!&#xA;We&amp;rsquo;ll start with the real camera on our RC and then we&amp;rsquo;ll also calibrate our simulator camera!&#xA;Once calibrated on the calibration images, you can use the same undistortion matrix for any other image that the same camera takes (given the focal length hasn&amp;rsquo;t changed)!&#xA;Calibrating your real camera I&amp;rsquo;ll be using my RC camera, the EleCam Explorer 4K, which has an advertised 170 degree FOV.</description>
    </item>
    <item>
      <title>Visualization: Saliency Maps</title>
      <link>http://localhost:1313/artificial-intelligence/visualization/saliency-maps/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/artificial-intelligence/visualization/saliency-maps/</guid>
      <description>Another useful visual tool to see how your network works is a saliency map. They were proposed back in 1998 by Itti, Koch and Niebur, a group of neuroscientists working on feature extraction in images, in a paper titled A Model of Saliency-based Visaul Attention for Rapid Scene Analysis.&#xA;In the context of Deep Learning and convolutional neural networks, they were first mentioned by the Visual Geometry Group at the University of Oxford, in a paper called Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</description>
    </item>
    <item>
      <title>Scale</title>
      <link>http://localhost:1313/rc-car/scale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/rc-car/scale/</guid>
      <description>&#xD;Most RC cars are scaled down versions of their real-life equivalent, so they&amp;rsquo;re expressed in ratios, the most common ones being (real-life size : RC model size):&#xA;1:18 1:16 1:10 1:8 there are also all sorts of scales in between those (and above/below) Of course, the question is: why do we care, and what&amp;rsquo;s better for a self-driving RC car?&#xA;It&amp;rsquo;s pretty simple:&#xA;a bigger RC car equals more real estate and more power to carry all of our gadgets on top of it, without damaging the motors while struggling with all of the weight, but a bigger car needs a bigger race track and road size we want to drive it on </description>
    </item>
    <item>
      <title>Static websites</title>
      <link>http://localhost:1313/extras/static-websites/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/extras/static-websites/</guid>
      <description>A static web page is delivered to the user exactly as stored on the server. By contrast, a dynamic web page first has to be generated using a web application. Which of course means that static websites display the same web pages for every user, as opposed to dynamic websites which can dynamically generate sites tailored to their users (at a significant cost and overhead). Static sites can still dynamically do stuff, but they have to do it at the user&amp;rsquo;s end (e.</description>
    </item>
    <item>
      <title>Visualization: donkey makemovie</title>
      <link>http://localhost:1313/artificial-intelligence/visualization/donkey-makemovie/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/artificial-intelligence/visualization/donkey-makemovie/</guid>
      <description>The makemovie command is a great tool to visually inspect and debug your model. Here are some example uses:&#xA;To create just a video of the training data, with an overlay that shows steering: donkey makemovie --tub=pathToYour/data/ --out=outputVideo.mp4&#xA;To create a video with an overlay of your model steering and the training data steering: donkey makemovie --tub=pathToYour/data/ --out=outputVideo.mp4 --model=yourModel.h5 --type=modelType&#xA;To create a video with a saliency map and both overlays: donkey makemovie --tub=pathToYour/data/ --out=outputVideo.</description>
    </item>
    <item>
      <title>RC Car body types</title>
      <link>http://localhost:1313/rc-car/body_type/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/rc-car/body_type/</guid>
      <description>The best body type for on road self-driving purposes is the standard race body type.&#xA;But to be thorough, we could roughly group all of the RC cars in 4 distinct categories:&#xA;RACE/STREET Probably the first thing that comes to mind when thinking of an RC car, a standard race car. This body type is the fastest and the best on paved, flat surfaces and is meant for on road use only.</description>
    </item>
    <item>
      <title>Electric motors</title>
      <link>http://localhost:1313/rc-car/electric_motors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/rc-car/electric_motors/</guid>
      <description>The main question concerning electric motors is: brushed or brushless? Brushed pros: cheaper, simpler, better for off-road.&#xA;Brushed cons: heavier, bigger, worse power efficiency (75-80%), they wear out in time.&#xA;Brushless pros: long lifespan, much better speed and handling, better power efficiency (85-90%).&#xA;Brushless cons: much more expensive, worse for off-road.&#xA;So what should we get? It depends on your budget, but brushed motors work just fine, and besides, for self-driving purposes, you don’t need a RC car that drives 100 KPH.</description>
    </item>
    <item>
      <title>Finding lane lines easier</title>
      <link>http://localhost:1313/artificial-intelligence/computer-vision-lane-finding/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/artificial-intelligence/computer-vision-lane-finding/</guid>
      <description>Remember we&amp;rsquo;ve showed before that our CNN is taking the horizon as the input feature, and that we&amp;rsquo;ll be addressing it after making a simulator mod that&amp;rsquo;ll allow us to take high res images. Well, here we are.&#xA;What we&amp;rsquo;re going to do To solve the horizon problem and simultaneously help the car recognize lane lines better, we&amp;rsquo;ll do the following:&#xA;Perform a perspective transform on every input image to get a birds-eye view of the road Convert the image to HLS color space, extract only the S channel and perform some thresholding on it to extract only the lanes from the input image Perspective transform There&amp;rsquo;s one really useful thing we can do with our input images, and we kinda already did it while we were calibrating our camera; a perspective transform.</description>
    </item>
    <item>
      <title>Reinforcement learning: letting the car learn to drive on its own</title>
      <link>http://localhost:1313/draft-and-todo/reinforcement-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/draft-and-todo/reinforcement-learning/</guid>
      <description>Using reinforcement learning in the real world for cars is pretty dangerous and expensive, since they&amp;rsquo;ll be crashing into everything they can at the very beginning. To counter this, we&amp;rsquo;ll be creating an OpenAI environment in which the car learns to drive by itself in order to pretrain weights for real life use.&#xA;Tried this, worked but wasn&amp;rsquo;t anything extraordinary, will think about writing it up! Take a look at the donkey-gym for examples if you really want to try it.</description>
    </item>
    <item>
      <title>You&#39;ll need:</title>
      <link>http://localhost:1313/extras/prerequisites/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/extras/prerequisites/</guid>
      <description>Git&#xA;Windows installer here. Linux instruction here (but it should come with Linux out of the box). Mac OS X installer here. A Markdown editor&#xA;I very much recommend Typora, I&amp;rsquo;m writing this using it. But you can use anything you like, even VS Code. A Hugo theme you like&#xA;You can see a list of themes, along with demos here. You can also search GitHub or the Web and find any other theme you&amp;rsquo;d like.</description>
    </item>
    <item>
      <title>Creating a website with Hugo</title>
      <link>http://localhost:1313/extras/creating-a-demo-website/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/extras/creating-a-demo-website/</guid>
      <description>Go to the folder where your Hugo binary is and run:&#xA;hugo new site quickstart Add the theme you&amp;rsquo;d like to your site&amp;rsquo;s themes directory:&#xA;cd quickstart git init # Replace the URL below with your theme git submodule add https://github.com/calintat/minimal.git themes/minimal If you&amp;rsquo;re wondering how to find the URL for your theme:&#xA;Assuming you&amp;rsquo;re on themes.gohugo.io and on your theme&amp;rsquo;s page, just copy the link from the download button and you&amp;rsquo;re good!</description>
    </item>
    <item>
      <title>Steering servo</title>
      <link>http://localhost:1313/rc-car/servo/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/rc-car/servo/</guid>
      <description>An RC servo is used for controlling the steering wheels of the car. It almost always comes with the RC car, so you shouldn’t worry about getting one.&#xA;It typically expects around 4.8V to 6V input on the power wire (varies by car) and a PWM control signal on the signal wire. Typically, the three wires are colored black-red-white, or brown-red-yellow, where:&#xA;the dark wire (black/brown) is ground, and the center wire (red) is power, and the light wire (white/yellow) is control.</description>
    </item>
    <item>
      <title>Electronic Speed Controller</title>
      <link>http://localhost:1313/rc-car/electronic_speed_controller/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/rc-car/electronic_speed_controller/</guid>
      <description>The role of the ESC is to take a RC PWM control signal (pulse between 1000 and 2000 microseconds) in, and use that to control the power to the motor so the motor spins with different amounts of power in forward or reverse. Many RC car kits come with an ESC preinstalled, in which case you should be just fine.&#xA;Again, 1500 microseconds typically means &amp;ldquo;center&amp;rdquo; which for the motor means &amp;ldquo;dead stop.</description>
    </item>
    <item>
      <title>Where will we be hosting the site?</title>
      <link>http://localhost:1313/extras/hosting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/extras/hosting/</guid>
      <description>I&amp;rsquo;d recommend using GitHub Pages or Netlify. The main difference is:&#xA;GitHub Pages just hosts your website, without any additional features, but you can host unlimited project sites. And yes, you can use a custom domain for each one. It&amp;rsquo;s also dead simple to use. You can use either Hugo or Jekyll or whatever you&amp;rsquo;d like. Netlify provides only one free website, for one team member, with 100 GB of bandwidth per month.</description>
    </item>
    <item>
      <title>Receiver</title>
      <link>http://localhost:1313/rc-car/receiver/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/rc-car/receiver/</guid>
      <description>If you buy a &amp;ldquo;kit car&amp;rdquo; that is listed as &amp;ldquo;needs a receiver,&amp;rdquo; then you don&amp;rsquo;t need to buy a receiver.&#xA;The Jetson Nano and the PWM/Servo driver will replace the receiver, outputting control signals to the car. If you’re buying a kit with a steering servo, motor, and ESC, you should actually try to not get a receiver, since the RC car could be specifically designed for that receivers PWM signals, and you’ll be taking it apart anyways.</description>
    </item>
    <item>
      <title>Using a custom domain</title>
      <link>http://localhost:1313/extras/using-a-custom-domain/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/extras/using-a-custom-domain/</guid>
      <description>It&amp;rsquo;s very easy to use a custom domain with both GitHub Pages and Netlify.&#xA;First, you need a custom domain. You can buy it from wherever you&amp;rsquo;d like, I&amp;rsquo;ll assume you&amp;rsquo;re using Namecheap.&#xA;Go to Namecheap domain search, find a domain you like and buy it.&#xA;Go to your hosting provider:&#xA;GitHub: Go to your repository, open up Settings, scroll down to the GitHub pages section and enter your domain. Netlify: Go to your website, open up Domain settings and add your domain as a custom domain.</description>
    </item>
    <item>
      <title>Advanced lane finding model</title>
      <link>http://localhost:1313/artificial-intelligence/integrating-the-lane-finding/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/artificial-intelligence/integrating-the-lane-finding/</guid>
      <description>The model will consist of two parallel CNNs, each of which end with a dense 100-unit layer, which we will then concatenate and pass through three additional dense layers, and end with two linear activations. The model should have about 6.5 million parameters, which take up about 2GB of VRAM, so we should be able to run it on our Jetson Nano with half that much RAM to spare. :)</description>
    </item>
    <item>
      <title>Batteries</title>
      <link>http://localhost:1313/rc-car/batteries/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/rc-car/batteries/</guid>
      <description>There are two types of batteries used for RC cars: Nickel Metal Hydride batteries (NiMH) and Lithium Polymer batteries (LiPo).&#xA;TL;DR: LiPo batteries are much better, but also more expensive.&#xA;Lithium Polymer batteries generally have higher current capacity (the amount of Amps the battery can deliver at one point while driving) as well as energy storage (the number of Amp Hours the battery stores when fully charged) so it may also last longer.</description>
    </item>
    <item>
      <title>Hardware inventory</title>
      <link>http://localhost:1313/hardware/inventory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/hardware/inventory/</guid>
      <description>Let’s start with a list of all of the hardware I’ll be using through this tutorial, and of course, with the money shot:&#xA;RC Car kit The RC Car I went with was the Tamiya TT-02, which came prebuilt and even included an receiver and a remote, for just a bit over 100€. Very lucky!&#xA;The reason I went with this is that it was just such a good deal for such a car.</description>
    </item>
    <item>
      <title>Raspisivanje math-a</title>
      <link>http://localhost:1313/draft-and-todo/derivacije/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/draft-and-todo/derivacije/</guid>
      <description>THIS IS A DRAFT&#xA;I&amp;rsquo;ll probably just delete this!&#xA;Nagib linije Recimo da imamo sljedeću funkciju: f(x) = x+1:&#xA;Želimo odrediti njezin nagib (slope). Nagib definiramo kao promjenu y u odnosu na promjenu x.&#xA;Nagib nam govori koliko brzo y raste ako promijenimo x.&#xA;Odaberemo bilo koju točku (x1,y1) na grafu. Nakon toga x povećamo za proizvoljnu veličinu Δx, te pogledamo koliko iznosi promjena Δy. Tako dobivamo drugu točku, (x1+Δx, y1+Δy), odnosno (x2, y2).</description>
    </item>
    <item>
      <title>Running the OS from an external SSD using a custom kernel</title>
      <link>http://localhost:1313/software/kernel-hacking/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/software/kernel-hacking/</guid>
      <description>This is the technical, optional upgrade that will enable you to boot your OS from an external SSD.&#xA;Syonyk has an awesome Jetson Nano guide with all of this stuff explained and was the primary source of info while researching how to do this.&#xA;JetsonHacks also have a guide that should make this much easier to do, as they’ve prepared scripts that do all of the work for you, but I haven’t tried it so I can’t say it works for sure, but it should!</description>
    </item>
    <item>
      <title>Assembling the RC Car</title>
      <link>http://localhost:1313/hardware/building-the-car/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/hardware/building-the-car/</guid>
      <description>Now to the fun part: building the RC car. This will vary very much based on your RC Car kit. If it’s ready-to-run (RTR), you should be good out of the box. If it’s an unassembled kit, you’ve got a ton of work ahead, just follow the instructions that came with the car. If you’re like me, and got something in between, you’ll have just a bit of work before running it.</description>
    </item>
    <item>
      <title>DonkeyCar</title>
      <link>http://localhost:1313/software/donkeycar/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/software/donkeycar/</guid>
      <description>Donkey is a high level self driving library written in Python. It was developed with a focus on enabling fast experimentation and easy contribution.&#xA;Source: Official Donkey docs&#xA;We&amp;rsquo;ll be using Donkey® as an interface between our RC car and the neural net we&amp;rsquo;d like to drive it for us.&#xA;As you can see above, we&amp;rsquo;d like to send the camera data from our RC to a model which would analyse it and tell the RC where to steer and how fast to go, in order to stay on the road.</description>
    </item>
    <item>
      <title>Master recipe: How to learn your machines</title>
      <link>http://localhost:1313/artificial-intelligence/how-to-train-your-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/artificial-intelligence/how-to-train-your-model/</guid>
      <description>These are notes I made while I was taking the Deeplearning.ai Deep Learning Specialization, more specifically, the awesome Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization course, through which Andrew Ng lays down a basic recipe for training your machines! I highly recommend you taking it, it&amp;rsquo;s free and you&amp;rsquo;ll absolutely learn something even if you&amp;rsquo;re an experienced ML practicioner.&#xA;This may very well be the most useful part of my project.</description>
    </item>
    <item>
      <title>Raspisivanje Hough transform-a</title>
      <link>http://localhost:1313/draft-and-todo/hough-transform/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/draft-and-todo/hough-transform/</guid>
      <description>THIS IS A DRAFT&#xA;I&amp;rsquo;ll probably just delete this!&#xA;Hough transform Linearnu funkciju u $xy$ - ravnini definiramo kao: $f(x) = y = ax + b$&#xA;U toj funkciji, $a$ i $b$ su fiksni i određuju nagib/smjer funkcije. Pravac $y = ax+b$ predstavlja sve moguće kombinacije $x$ i $y$ uz zadane $a$ i $b$.&#xA;Pretpostavimo da znamo dvije točke na tom pravcu (dvije moguće kombinacije $x$ i $y$ za zadane $a$ i $b$):</description>
    </item>
    <item>
      <title>DonkeyCar installation: Host PC</title>
      <link>http://localhost:1313/software/donkeycar-host/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/software/donkeycar-host/</guid>
      <description>Let&amp;rsquo;s install the Donkey software on your host PC. The only part where this differs between the three platforms, Mac OS X, Linux and Windows, is in the Miniconda software installation, so we&amp;rsquo;ll get that out of the way first.&#xA;Mac OS X Download and install: Miniconda here, git here Open up a terminal and follow the rest of the tutorial Windows Download and install: Miniconda here, git here Open an Anaconda Prompt via Start Menu and follow the rest of the tutorial Linux Download Miniconda here and install it Open up a terminal and follow the rest of the tutorial The rest of the tutorial: Go to a place where you want the stuff we&amp;rsquo;ll be working on to be.</description>
    </item>
    <item>
      <title>Adding behaviours: automated lane changing</title>
      <link>http://localhost:1313/artificial-intelligence/adding-behaviours/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/artificial-intelligence/adding-behaviours/</guid>
      <description>The only thing left to do, in order to test my idea with multiple specialized networks converging into a final decision layer, is to implement the behavioural specialized network.&#xA;This is what the model will look like:&#xA;The behavioural part of the network can be seen just before the 100-unit dense layer.&#xA;Here it is in action: note the lower left terminal to see when I pressed the button to change lanes</description>
    </item>
    <item>
      <title>Building the mounting plates for the hardware</title>
      <link>http://localhost:1313/hardware/mounting-plates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/hardware/mounting-plates/</guid>
      <description>There are many options to go for when it comes to mounting your Nano and the rest of the hardware to your RC car.&#xA;Option 1: 3D printing If you’re planning on 3D printing your parts, take a look at:&#xA;The official DonkeyCar docs which contain a lot of 3D models for printing: chassis and adapters, mounting plates, more mounting plates, etc. Markku.ai’s Chilicorn Rail for the Tamiya cars I actually used the Chilicorn Rail for the first iteration of my build, and was very lucky to have been introduced by my mentor to Mitch, who printed out the parts and helped me out with a ton of stuff since then:</description>
    </item>
    <item>
      <title>DonkeyCar Installation: The Simulator</title>
      <link>http://localhost:1313/software/donkeycar-simulator/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/software/donkeycar-simulator/</guid>
      <description>Even if you don&amp;rsquo;t have an RC car, you can start here and follow the rest of the project by just substituting the RC car with the simulator!&#xA;This is one of the coolest parts of DonkeyCar for me, and probably one of the most useful ones. It&amp;rsquo;s also a good way to get your feet wet with this kind of a project without building an actual RC. If it turns out you like it, you can always go back to the beginning and build an actual platform.</description>
    </item>
    <item>
      <title>Detecting and tracking objects on images</title>
      <link>http://localhost:1313/artificial-intelligence/object-detection-and-tracking/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/artificial-intelligence/object-detection-and-tracking/</guid>
      <description>&#xD;Implemented. Need to sit down and write it up! </description>
    </item>
    <item>
      <title>DonkeyCar installation: RC car</title>
      <link>http://localhost:1313/software/donkeycar-rc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/software/donkeycar-rc/</guid>
      <description>Connecting to your RC via SSH To connect and work with your RC throughout the rest of the project, you&amp;rsquo;ll need two things:&#xA;An SSH client The IP address of your RC SSH Clients: If you&amp;rsquo;re using Linux or a Mac, you&amp;rsquo;re all set. They come with a SSH client pre-installed, and you just need to open up a terminal and type:&#xA;ssh username@ipAddress If you&amp;rsquo;re using Windows, you need to install one.</description>
    </item>
    <item>
      <title>Preparing the Jetson Nano</title>
      <link>http://localhost:1313/hardware/jetson-nano-installation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/hardware/jetson-nano-installation/</guid>
      <description>Before we begin assembling our hardware together, we should first prepare our Jetson Nano by installing an OS on it and verifying everything works before it gets buried among all the other hardware on the RC.&#xA;Preparing the microSD First, we&amp;rsquo;ll prepare the microSD by installing an OS on it for the Nano to run.&#xA;The official Jetson Nano docs are great and you can just follow them until the Next Steps step.</description>
    </item>
    <item>
      <title>Assembling the Jetson Nano</title>
      <link>http://localhost:1313/hardware/assembling-the-nano/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/hardware/assembling-the-nano/</guid>
      <description>Now we can finish up our Nano by connecting the WLAN card, microSD and the fan to it.&#xA;Plugging in the microSD I actually already did a lot of assembly some time ago, and I&amp;rsquo;m writing this in retrospect, so don&amp;rsquo;t be worried if my Nano has a lot of stuff already hooked up to it and if it looks a bit different than yours, just focus on the stuff we&amp;rsquo;re going through and disregard the rest.</description>
    </item>
    <item>
      <title>Connecting the RC to the Nano</title>
      <link>http://localhost:1313/hardware/connecting-the-car-to-the-nano/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/hardware/connecting-the-car-to-the-nano/</guid>
      <description>Now comes the part that should differ the most, based on the RC you got. But don&amp;rsquo;t worry, it&amp;rsquo;s very much doable no matter the RC you got!&#xA;Finding your ESC/Servo The first thing you should do is find your ESC and your Servo connectors, which should be a three wire connector coming from your RC car.&#xA;If you&amp;rsquo;ve bought a car that came with a wireless receiver, both the connectors should be connected to it.</description>
    </item>
    <item>
      <title>DonkeyCar configuration: RC car</title>
      <link>http://localhost:1313/software/setting-up-donkeycar-on-the-rc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/software/setting-up-donkeycar-on-the-rc/</guid>
      <description>From now until the end of this chapter, I&amp;rsquo;ll assume you&amp;rsquo;re working on your car via SSH.&#xA;Creating a DonkeyCar application First, we&amp;rsquo;ll run the createcar command, which will create a new directory with all of the files needed to run and train our RC.&#xA;Command usage from the docs:&#xA;donkey createcar --path &amp;lt;dir&amp;gt; [--overwrite] [--template &amp;lt;donkey2&amp;gt;] Run the following command to create a new donkeycar application:&#xA;donkey createcar --path ~/mycar Open the newly created directory:</description>
    </item>
    <item>
      <title>Calibrating steering and throttle</title>
      <link>http://localhost:1313/software/calibrating-steering-and-throttle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/software/calibrating-steering-and-throttle/</guid>
      <description>Make sure your car wheels are not touching the ground. Prop it up using a shoebox, or in my case, an eGPU dock. We will be calibrating the throttle which means your car will start accelerating very fast, without warning, so you wouldn&amp;rsquo;t want it slamming into a wall at full throttle.&#xA;Calibrating the throttle: First, you&amp;rsquo;ll need to turn on your car; the actual RC, not the Nano.</description>
    </item>
    <item>
      <title>Using a gamepad</title>
      <link>http://localhost:1313/software/connecting-a-bluetooth-gamepad/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/software/connecting-a-bluetooth-gamepad/</guid>
      <description>You can, and should, use a gamepad to control your RC. It&amp;rsquo;s much easier to generate good training data using a gamepad, and it&amp;rsquo;s much easier to drive the thing compared to the Web interface that Donkey provides.&#xA;So how do we connect and use one?&#xA;Compatible controllers First, let&amp;rsquo;s make sure you have one that&amp;rsquo;ll actually work&#xA;The official Donkey docs list that the following are known to work:</description>
    </item>
    <item>
      <title>Test drive</title>
      <link>http://localhost:1313/software/test-driving-the-rc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/software/test-driving-the-rc/</guid>
      <description>First of all: congrats on getting this far! Let&amp;rsquo;s spin our RC for a ride.&#xA;Before continuing:&#xA;Make sure your RC is powered up (not the Jetson Nano, the actual RC). Make sure that the camera is connected and powered up (if you&amp;rsquo;re using a USB camera). Make sure that your RC has enough space around it, depending on what throttle values you&amp;rsquo;ve defined. Test drive using a gamepad Change to the directory you&amp;rsquo;ve created with the donkey createcar command:</description>
    </item>
    <item>
      <title>First Autopilot: sanity check</title>
      <link>http://localhost:1313/software/sanity-check---first-autopilot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/software/sanity-check---first-autopilot/</guid>
      <description>After doing a bunch of work like we just did, it&amp;rsquo;s always important to periodically check that everything works as intended, before moving on to even more complex stuff.&#xA;So that&amp;rsquo;s what we&amp;rsquo;ll be doing.&#xA;Building a test track First, you need to build a test track. For this sanity checking, I wouldn&amp;rsquo;t do anything over the top. Just take some duct-tape and make a circular track that&amp;rsquo;s easy to drive around.</description>
    </item>
  </channel>
</rss>
